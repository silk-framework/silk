
# Setting the default internal dataset.
dataset.internal.plugin = inMemory
vocabulary.manager.plugin = rdf

#####################
# Mapping Preview
#####################

# Maximum size in Kilobytes of a file that must be loaded into memory in order to get a mapping preview. This applies to XML and JSON datasets.
mapping.preview.max.file.size.kb = 5000 # 2MB

##### Graph Store ###
graphstore.default = {
  # Timeout in which a connection must be established
  connection.timeout.ms = 15000 # 15s
  # Timeout in which a response must be read
  read.timeout.ms = 150000 # 150s
  # Max request size of a single GraphStore request, larger data is split into multiple requests
  max.request.size = 300000000 # 300MB
  # Timeout in which a file upload of size max.request.size must be uploaded
  fileUpload.timeout.ms = 1800000 # half hour
}

##### Remote SPARQL endpoint ###
silk.remoteSparqlEndpoint.defaults = {
  connection.timeout.ms = 15000 # 15s
  read.timeout.ms = 180000 # 180s
}

# Provenance
provenance.persistWorkflowProvenancePlugin.plugin = nopWorkflowProvenance

# Security
plugin.parameters.password.crypt.key = "8RNYItRSDHrT8WyV" # AES crypto key, change for production use

# Plugins
# Blacklist plugins by plugin ID in a comma separated list
# plugin.blacklist = "sparqlSelectOperator"

######################
# Linking Execution
######################
linking.execution = {
  # the maximum amount of links that are generated in the linking execution/evaluation
  linkLimit = {
    # The default value a link spec is initialized with, this can be changed for each link spec.
    default = 1000000 # 1 million
    # The absolute maximum of links that can be generated. This is necessary since the links are kept in-memory.
    max = 10000000 # 10 million
  }
  # The maximum time the matching task is allowed to run, this does not limit the loading time.
  matching.timeout.seconds = 3600 # 1 hour
}

###############################################
### Optimizations
###############################################

### Push filter into (SPARQL) data source in linking execution (Disabled by default because they do not work correctly, yet, because of 'required' attribute semantics, i.e. if required==false, this may lead to false results)
optimizations.linking.execution.pushFilters.enabled = false
##### Remove "OR" filter clauses that contain at least one in-equality. Usually this kind of filter has a negative effect instead of positive.
optimizations.linking.execution.pushFilters.removeDisjunctionsWithInEqualities = true

###############################################
### Compatibility fixes
###############################################
# For some reasons different implementations are (sometimes) used on the CI server in the tests
javax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl
javax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl


###############################################
### Workspace
###############################################
# The time in milliseconds that a DI client will wait for the workspace to be initialized. This does not apply for the client that triggered the init.
workspace.timeouts.waitForWorkspaceInitialization = 5000 // 5 seconds

###############################################
### Caches
###############################################
# Automatically run auto-run activities
caches.config.enableAutoRun=true

###############################################
### Safety
###############################################

# Mode that prevents accessing external services outside of workflows. Default false
config.production.safeMode = false